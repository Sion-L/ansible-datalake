{% set mysqlconn = groups['mysql'][0] %}
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
 
<configuration>
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://{{ hostvars[mysqlconn].datalake_host }}:3306/hive?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=UTF-8</value>
    <description>JDBC connect string for a JDBC metastore</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>{{ mysql_hadoop_account }}</value>
    <description>username to use against metastore database</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>{{ mysql_hadoop_account_password }}</value>
    <description>password to use against metastore database</description>
  </property>
  <property>
     <name>hive.metastore.uris</name>
     <value>thrift://{{ hostvars[mysqlconn].datalake_host }}:9083</value>
  </property>
  <property>
     <name>hive.server2.thrift.bind.host</name>
     <value>{{ hostvars[mysqlconn].datalake_host }}</value>
  </property>
  <property>
     <name>hive.server2.thrift.port</name>
     <value>10000</value>
  </property>
  <property>
    <name>hive.server2.webui.host</name>
    <value>{{ hostvars[mysqlconn].datalake_host }}</value>
  </property>
  <property>
    <name>hive.server2.webui.port</name>
    <value>10002</value>
  </property>
  <property>
    <name>hive.server2.enable.doAs</name>
    <value>true</value>
  </property>
 
  <property>
    <name>hive.metastore.schema.verification</name>
    <value>false</value>
  </property>
  <property>
    <name>hive.exec.local.scratchdir</name>
    <value>{{ hive_tmp_dir }}</value>
    <description>Local scratch space for Hive jobs</description>
  </property>
  <property>
    <name>hive.exec.scratchdir</name>
    <value>{{ hive_scratch_dir }}</value>
  </property>
  <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>{{ hive_warehouse_dir }}</value>
    <description>location of default database for the warehouse</description>
  </property>
  <property>
    <name>hive.querylog.location</name>
    <value>{{ hive_querylog_dir }}</value>
    <description>Location of Hive run time structured log file</description>
  </property>
  <property>
    <name>hive.server2.logging.operation.log.location</name>
    <value>{{ hive_oplog_dir }}</value>
    <description>Top level directory where operation logs are stored if logging functionality is enabled</description>
  </property>
  <property>
    <name>hive.security.authorization.sqlstd.confwhitelist</name>
    <value>mapred.*|hive.*|mapreduce.*|spark.*|iceberg.*|yarn.*</value>
  </property>
   
  <property>
   <name>hive.security.authorization.sqlstd.confwhitelist.append</name>
    <value>mapred.*|hive.*|mapreduce.*|spark.*|iceberg.*|yarn.*</value>
  </property>
  <property>
    <name>hive.downloaded.resources.dir</name>
    <value>{{ hive_download_dir }}/${hive.session.id}_resources</value>
    <description>Temporary local directory for added resources in the remote file system.</description>
  </property>
  <property>
    <name>datanucleus.schema.autoCreateAll</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.resultset.use.unique.column.names</name>
    <value>false</value>
  </property>
  <property>
    <name>hive.cli.print.header</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.server2.session.check.interval</name>
    <value>30s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      The time should be bigger than or equal to 3000 msec.
      The check interval for session/operation timeout, which can be disabled by setting to zero or negative value.
      5s
    </description>
  </property>
  <property>
    <name>hive.server2.idle.session.timeout</name>
    <value>30s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      Session will be closed when it's not accessed for this duration, which can be disabled by setting to zero or negative value.
      15s
    </description>
  </property>
  <property>
    <name>hive.server2.idle.operation.timeout</name>
    <value>30s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      Operation will be closed when it's not accessed for this duration of time, which can be disabled by setting to zero value.
        With positive value, it's checked for operations in terminal state only (FINISHED, CANCELED, CLOSED, ERROR).
        With negative value, it's checked for all of the operations regardless of state.
        10s
    </description>
  </property>
  <property>
    <name>hive.server2.authentication</name>
    <value>NONE</value>
    <description>
      Expects one of [nosasl, none, ldap, kerberos, pam, custom].
      Client authentication types.
        NONE: no authentication check
        LDAP: LDAP/AD based authentication
        KERBEROS: Kerberos/GSSAPI authentication
        CUSTOM: Custom authentication provider
                (Use with property hive.server2.custom.authentication.class)
        PAM: Pluggable authentication module
        NOSASL:  Raw transport
    </description>
  </property>
  <property>
    <name>hive.compute.query.using.stats</name>
    <value>false</value>
  </property>
  <property>
    <name>hive.zookeeper.quorum</name>
    <value>{%- for host in groups['zookeeper'] -%}
    {{ hostvars[host]['datalake_host'] }}:2181{% if not loop.last %},{% endif %}{%- endfor %}</value>
    <description>
      List of ZooKeeper servers to talk to. This is needed for:
      1. Read/write locks - when hive.lock.manager is set to
      org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager,
      2. When HiveServer2 supports service discovery via Zookeeper.
      3. For delegation token storage if zookeeper store is used, if
      hive.cluster.delegation.token.store.zookeeper.connectString is not set
      4. LLAP daemon registry service
      5. Leader selection for privilege synchronizer
    </description>
  </property>
  <property>
    <name>hive.fetch.task.conversion</name>
    <value>more</value>
    <description>
      Expects one of [none, minimal, more].
      Some select queries can be converted to single FETCH task minimizing latency.
      Currently the query should be single sourced not having any subquery and should not have
      any aggregations or distincts (which incurs RS), lateral views and joins.
      0. none : disable hive.fetch.task.conversion
      1. minimal : SELECT STAR, FILTER on partition columns, LIMIT only
      2. more    : SELECT, FILTER, LIMIT only (support TABLESAMPLE and virtual columns)
    </description>
  </property>
  <property>
    <name>hive.exec.mode.local.auto</name>
    <value>false</value>
    <description>Let Hive determine whether to run in local mode automatically</description>
  </property>
  <property>
    <name>mapreduce.job.queuename</name>
    <value>root.default</value>
  </property>
 
  <property>
    <name>hive.server2.thrift.max.worker.threads</name>
    <value>500</value>
    <description>Minimum number of Thrift worker threads</description>
  </property>
  <property>
    <name>hive.server2.thrift.min.worker.threads</name>
    <value>10</value>
    <description>Minimum number of Thrift worker threads</description>
  </property>
   
</configuration>
